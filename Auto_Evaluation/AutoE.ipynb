{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7265444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2025 Microsoft Corporation.\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import cast\n",
    "\n",
    "import pandas as pd\n",
    "from pydantic import SecretStr\n",
    "from rich import print as rich_print\n",
    "\n",
    "from benchmark_qed.autoe.pairwise_scores import analyze_criteria, get_pairwise_scores\n",
    "from benchmark_qed.autoe.reference_scores import (\n",
    "    get_reference_scores,\n",
    "    summarize_reference_scores,\n",
    ")\n",
    "from benchmark_qed.cli.utils import print_df\n",
    "from benchmark_qed.config.llm_config import (\n",
    "    LLMConfig,\n",
    "    LLMProvider,\n",
    ")\n",
    "from benchmark_qed.config.model.score import (\n",
    "    pairwise_scores_criteria,\n",
    "    reference_scores_criteria,\n",
    ")\n",
    "from benchmark_qed.llm.factory import ModelFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b7f029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da1b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\NLP\\GraphRag_Eval\\autoe\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c25c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22b56004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config LLM model to be used as judge\n",
    "llm_config = LLMConfig(\n",
    "    model=\"gpt-5-nano\",\n",
    "    api_key=SecretStr(os.environ[\"OPENAI_API_KEY\"]),\n",
    "    llm_provider=LLMProvider.OpenAIChat,\n",
    "    concurrent_requests=32,\n",
    "    call_args={\"temperature\": 1.0, \"seed\": 42},\n",
    ")\n",
    "llm_client = ModelFactory.create_chat_model(llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c4b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config conditions for comparison\n",
    "base = \"vector_rag\"\n",
    "others = [\"lazygraphrag\", \"graphrag_global\"]\n",
    "question_sets = [\"activity_global\", \"activity_local\"]\n",
    "trials = 2  # number of trials to run for each combination of [query, base, other]. Trials must be an even number to support counterbalancing.\n",
    "alpha = 0.05  # significance level used for statistical tests\n",
    "\n",
    "input_dir = \"GraphRag_Eval/autoe\"\n",
    "output_dir = Path(\"./output/win_rates\")\n",
    "if not output_dir.exists():\n",
    "    output_dir.mkdir(parents=True)\n",
    "\n",
    "# load default criteria. You can also define your own criteria as a list Criteria objects\n",
    "criteria = pairwise_scores_criteria()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65581797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing vector_rag vs lazygraphrag for question set: activity_global\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing vector_rag vs lazygraphrag for question set: activity_global\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\shash\\anaconda3\\envs\\benchmark\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\shash\\anaconda3\\envs\\benchmark\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing vector_rag vs graphrag_global for question set: activity_global\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing vector_rag vs graphrag_global for question set: activity_global\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\shash\\anaconda3\\envs\\benchmark\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\shash\\anaconda3\\envs\\benchmark\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing vector_rag vs lazygraphrag for question set: activity_local\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing vector_rag vs lazygraphrag for question set: activity_local\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\shash\\anaconda3\\envs\\benchmark\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\shash\\anaconda3\\envs\\benchmark\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Processing vector_rag vs graphrag_global for question set: activity_local\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Processing vector_rag vs graphrag_global for question set: activity_local\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\shash\\anaconda3\\envs\\benchmark\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\shash\\anaconda3\\envs\\benchmark\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shash\\anaconda3\\envs\\benchmark\\Lib\\site-packages\\benchmark_qed\\autoe\\pairwise_scores.py:273: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  shapiro_base = shapiro(base_scores)\n",
      "c:\\Users\\shash\\anaconda3\\envs\\benchmark\\Lib\\site-packages\\benchmark_qed\\autoe\\pairwise_scores.py:274: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  shapiro_other = shapiro(other_scores)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                 Win Rates Summary                                                 </span>\n",
       "┏━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> question_set    </span>┃<span style=\"font-weight: bold\"> criteria          </span>┃<span style=\"font-weight: bold\"> base_name  </span>┃<span style=\"font-weight: bold\"> other_name      </span>┃<span style=\"font-weight: bold\"> base_mean </span>┃<span style=\"font-weight: bold\"> other_mean </span>┃<span style=\"font-weight: bold\"> formatted_correc… </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ activity_global │ comprehensiveness │ vector_rag │ graphrag_global │ 0.0       │ 1.0        │ 0.315             │\n",
       "│ activity_global │ comprehensiveness │ vector_rag │ lazygraphrag    │ 0.0       │ 1.0        │ 0.315             │\n",
       "│ activity_global │ diversity         │ vector_rag │ graphrag_global │ 0.0       │ 1.0        │ 0.315             │\n",
       "│ activity_global │ diversity         │ vector_rag │ lazygraphrag    │ 0.0       │ 1.0        │ 0.315             │\n",
       "│ activity_global │ empowerment       │ vector_rag │ graphrag_global │ 0.0       │ 1.0        │ 0.315             │\n",
       "│ activity_global │ empowerment       │ vector_rag │ lazygraphrag    │ 0.0       │ 1.0        │ 0.315             │\n",
       "│ activity_global │ relevance         │ vector_rag │ graphrag_global │ 0.25      │ 0.75       │ 0.317             │\n",
       "│ activity_global │ relevance         │ vector_rag │ lazygraphrag    │ 0.0       │ 1.0        │ 0.315             │\n",
       "│ activity_local  │ comprehensiveness │ vector_rag │ graphrag_global │ 1.0       │ 0.0        │ 0.315             │\n",
       "│ activity_local  │ comprehensiveness │ vector_rag │ lazygraphrag    │ 0.0       │ 1.0        │ 0.315             │\n",
       "│ activity_local  │ diversity         │ vector_rag │ graphrag_global │ 1.0       │ 0.0        │ 0.315             │\n",
       "│ activity_local  │ diversity         │ vector_rag │ lazygraphrag    │ 0.0       │ 1.0        │ 0.315             │\n",
       "│ activity_local  │ empowerment       │ vector_rag │ graphrag_global │ 1.0       │ 0.0        │ 0.315             │\n",
       "│ activity_local  │ empowerment       │ vector_rag │ lazygraphrag    │ 0.25      │ 0.75       │ 0.317             │\n",
       "│ activity_local  │ relevance         │ vector_rag │ graphrag_global │ 1.0       │ 0.0        │ 0.315             │\n",
       "│ activity_local  │ relevance         │ vector_rag │ lazygraphrag    │ 0.25      │ 0.75       │ 0.317             │\n",
       "└─────────────────┴───────────────────┴────────────┴─────────────────┴───────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                 Win Rates Summary                                                 \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mquestion_set   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mcriteria         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mbase_name \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mother_name     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mbase_mean\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mother_mean\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mformatted_correc…\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ activity_global │ comprehensiveness │ vector_rag │ graphrag_global │ 0.0       │ 1.0        │ 0.315             │\n",
       "│ activity_global │ comprehensiveness │ vector_rag │ lazygraphrag    │ 0.0       │ 1.0        │ 0.315             │\n",
       "│ activity_global │ diversity         │ vector_rag │ graphrag_global │ 0.0       │ 1.0        │ 0.315             │\n",
       "│ activity_global │ diversity         │ vector_rag │ lazygraphrag    │ 0.0       │ 1.0        │ 0.315             │\n",
       "│ activity_global │ empowerment       │ vector_rag │ graphrag_global │ 0.0       │ 1.0        │ 0.315             │\n",
       "│ activity_global │ empowerment       │ vector_rag │ lazygraphrag    │ 0.0       │ 1.0        │ 0.315             │\n",
       "│ activity_global │ relevance         │ vector_rag │ graphrag_global │ 0.25      │ 0.75       │ 0.317             │\n",
       "│ activity_global │ relevance         │ vector_rag │ lazygraphrag    │ 0.0       │ 1.0        │ 0.315             │\n",
       "│ activity_local  │ comprehensiveness │ vector_rag │ graphrag_global │ 1.0       │ 0.0        │ 0.315             │\n",
       "│ activity_local  │ comprehensiveness │ vector_rag │ lazygraphrag    │ 0.0       │ 1.0        │ 0.315             │\n",
       "│ activity_local  │ diversity         │ vector_rag │ graphrag_global │ 1.0       │ 0.0        │ 0.315             │\n",
       "│ activity_local  │ diversity         │ vector_rag │ lazygraphrag    │ 0.0       │ 1.0        │ 0.315             │\n",
       "│ activity_local  │ empowerment       │ vector_rag │ graphrag_global │ 1.0       │ 0.0        │ 0.315             │\n",
       "│ activity_local  │ empowerment       │ vector_rag │ lazygraphrag    │ 0.25      │ 0.75       │ 0.317             │\n",
       "│ activity_local  │ relevance         │ vector_rag │ graphrag_global │ 1.0       │ 0.0        │ 0.315             │\n",
       "│ activity_local  │ relevance         │ vector_rag │ lazygraphrag    │ 0.25      │ 0.75       │ 0.317             │\n",
       "└─────────────────┴───────────────────┴────────────┴─────────────────┴───────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run pairwise comparisons for each question set and each pair of [base, other].\n",
    "all_results = []\n",
    "for question_set in question_sets:\n",
    "    for other in others:\n",
    "        rich_print(f\"Processing {base} vs {other} for question set: {question_set}\")\n",
    "        result = get_pairwise_scores(\n",
    "            llm_client=llm_client,\n",
    "            llm_config=llm_config,\n",
    "            base_name=base,\n",
    "            other_name=other,\n",
    "            base_answers=pd.read_json(f\"{input_dir}/{base}/{question_set}.json\"),\n",
    "            other_answers=pd.read_json(f\"{input_dir}/{other}/{question_set}.json\"),\n",
    "            criteria=criteria,\n",
    "            trials=trials,\n",
    "            include_score_id_in_prompt=True,\n",
    "            question_id_key=\"question_id\",\n",
    "        )\n",
    "        result[\"question_set\"] = question_set\n",
    "        all_results.append(result)\n",
    "\n",
    "        # save pairwise results for each question set and pair of [base, other]\n",
    "        result.to_csv(\n",
    "            output_dir / f\"{question_set}_{base}--{other}.csv\",\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "# save all pairwise results in a single file\n",
    "all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "all_results_df.to_csv(output_dir / \"win_rates.csv\", index=False)\n",
    "\n",
    "# perform significance testing on the results\n",
    "significance_test_results = analyze_criteria(\n",
    "    all_results_df,\n",
    "    alpha=alpha,\n",
    ")\n",
    "significance_test_results.to_csv(output_dir / \"winrates_sig_tests.csv\", index=False)\n",
    "\n",
    "print_df(\n",
    "    cast(\n",
    "        pd.DataFrame,\n",
    "        significance_test_results[\n",
    "            [\n",
    "                \"question_set\",\n",
    "                \"criteria\",\n",
    "                \"base_name\",\n",
    "                \"other_name\",\n",
    "                \"base_mean\",\n",
    "                \"other_mean\",\n",
    "                \"formatted_corrected_p_value\",\n",
    "            ]\n",
    "        ],\n",
    "    ),\n",
    "    \"Win Rates Summary\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4828aca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Model usage statistics:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Model usage statistics:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-5-nano'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">127501</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">88639</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">216140</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_cached_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'completion_reasoning_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72768</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'accepted_prediction_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'rejected_prediction_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'total_calls'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'model'\u001b[0m: \u001b[32m'gpt-5-nano'\u001b[0m,\n",
       "    \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m127501\u001b[0m,\n",
       "    \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m88639\u001b[0m,\n",
       "    \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m216140\u001b[0m,\n",
       "    \u001b[32m'prompt_cached_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "    \u001b[32m'completion_reasoning_tokens'\u001b[0m: \u001b[1;36m72768\u001b[0m,\n",
       "    \u001b[32m'accepted_prediction_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "    \u001b[32m'rejected_prediction_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "    \u001b[32m'total_calls'\u001b[0m: \u001b[1;36m64\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rich_print(\"Model usage statistics:\")\n",
    "rich_print(llm_client.get_usage())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bd1ca2",
   "metadata": {},
   "source": [
    "Assertion Based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09fe9be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "assertions_file = \"activity_global_assertions.json\"\n",
    "generated_rag = \"vector_rag\"\n",
    "pass_threshold = 0.5\n",
    "trials = 4  # number of trials\n",
    "\n",
    "input_dir = \"./example_answers\"\n",
    "output_dir = Path(\"./output/assertion_scores\")\n",
    "if not output_dir.exists():\n",
    "    output_dir.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fab4e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\shash\\anaconda3\\envs\\benchmark\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\shash\\anaconda3\\envs\\benchmark\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                       Assertion Scores Summary by Question                                        </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> question                                                                                       </span>┃<span style=\"font-weight: bold\"> success </span>┃<span style=\"font-weight: bold\"> fail </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━┩\n",
       "│ Across the dataset, how are legal, political, and social issues linked to the emergence of     │ 3       │ 1    │\n",
       "│ public health crises?                                                                          │         │      │\n",
       "│ Across the dataset, what are the common themes and narratives associated with public health    │ 2       │ 2    │\n",
       "│ crises?                                                                                        │         │      │\n",
       "└────────────────────────────────────────────────────────────────────────────────────────────────┴─────────┴──────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                       Assertion Scores Summary by Question                                        \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mquestion                                                                                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1msuccess\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mfail\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━┩\n",
       "│ Across the dataset, how are legal, political, and social issues linked to the emergence of     │ 3       │ 1    │\n",
       "│ public health crises?                                                                          │         │      │\n",
       "│ Across the dataset, what are the common themes and narratives associated with public health    │ 2       │ 2    │\n",
       "│ crises?                                                                                        │         │      │\n",
       "└────────────────────────────────────────────────────────────────────────────────────────────────┴─────────┴──────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; font-style: italic\">3 Failed Assertions</span><span style=\"font-style: italic\">                                                </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> question                              </span>┃<span style=\"font-weight: bold\"> assertion                             </span>┃<span style=\"font-weight: bold\"> score_mean </span>┃<span style=\"font-weight: bold\"> score_std          </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Across the dataset, how are legal,    │ The response should explicitly link   │ 0.5        │ 0.5                │\n",
       "│ political, and social issues linked   │ legal issues, such as legislation and │            │                    │\n",
       "│ to the emergence of public health     │ court decisions, to the emergence or  │            │                    │\n",
       "│ crises?                               │ exacerbation of public health crises, │            │                    │\n",
       "│                                       │ providing concrete examples from the  │            │                    │\n",
       "│                                       │ dataset.                              │            │                    │\n",
       "│ Across the dataset, what are the      │ The response should discuss           │ 0.25       │ 0.4330127018922193 │\n",
       "│ common themes and narratives          │ challenges faced in addressing public │            │                    │\n",
       "│ associated with public health crises? │ health crises, including factors like │            │                    │\n",
       "│                                       │ distrust in science, financial        │            │                    │\n",
       "│                                       │ constraints, and policy barriers.     │            │                    │\n",
       "│ Across the dataset, what are the      │ The response should mention           │ 0.5        │ 0.5                │\n",
       "│ common themes and narratives          │ strategies and systems for crisis     │            │                    │\n",
       "│ associated with public health crises? │ management, such as vaccination       │            │                    │\n",
       "│                                       │ campaigns, public health              │            │                    │\n",
       "│                                       │ infrastructure, international         │            │                    │\n",
       "│                                       │ cooperation, and community health     │            │                    │\n",
       "│                                       │ centers.                              │            │                    │\n",
       "└───────────────────────────────────────┴───────────────────────────────────────┴────────────┴────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                \u001b[0m\u001b[1;3;31m3 Failed Assertions\u001b[0m\u001b[3m                                                \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mquestion                             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1massertion                            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mscore_mean\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mscore_std         \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Across the dataset, how are legal,    │ The response should explicitly link   │ 0.5        │ 0.5                │\n",
       "│ political, and social issues linked   │ legal issues, such as legislation and │            │                    │\n",
       "│ to the emergence of public health     │ court decisions, to the emergence or  │            │                    │\n",
       "│ crises?                               │ exacerbation of public health crises, │            │                    │\n",
       "│                                       │ providing concrete examples from the  │            │                    │\n",
       "│                                       │ dataset.                              │            │                    │\n",
       "│ Across the dataset, what are the      │ The response should discuss           │ 0.25       │ 0.4330127018922193 │\n",
       "│ common themes and narratives          │ challenges faced in addressing public │            │                    │\n",
       "│ associated with public health crises? │ health crises, including factors like │            │                    │\n",
       "│                                       │ distrust in science, financial        │            │                    │\n",
       "│                                       │ constraints, and policy barriers.     │            │                    │\n",
       "│ Across the dataset, what are the      │ The response should mention           │ 0.5        │ 0.5                │\n",
       "│ common themes and narratives          │ strategies and systems for crisis     │            │                    │\n",
       "│ associated with public health crises? │ management, such as vaccination       │            │                    │\n",
       "│                                       │ campaigns, public health              │            │                    │\n",
       "│                                       │ infrastructure, international         │            │                    │\n",
       "│                                       │ cooperation, and community health     │            │                    │\n",
       "│                                       │ centers.                              │            │                    │\n",
       "└───────────────────────────────────────┴───────────────────────────────────────┴────────────┴────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">3</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> assertions failed. See output\\assertion_scores\\assertion_scores.csv for details.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31m3\u001b[0m\u001b[1;31m assertions failed. See output\\assertion_scores\\assertion_scores.csv for details.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from benchmark_qed.autoe.assertion_scores import get_assertion_scores\n",
    "\n",
    "answers = pd.read_json(\"E:/NLP/GraphRag_Eval/autoe/vector_rag/activity_global.json\")\n",
    "\n",
    "assertions = (\n",
    "    pd.read_json(\"E:/NLP/GraphRag_Eval/autoe/activity_global_assertions.json\")\n",
    "    .explode(\"assertions\")\n",
    "    .rename(columns={\"assertions\": \"assertion\"})\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "assertion_score = get_assertion_scores(\n",
    "    llm_client=llm_client,\n",
    "    llm_config=llm_config,\n",
    "    answers=answers,\n",
    "    assertions=assertions,\n",
    "    trials=4,\n",
    "    question_id_key=\"question_id\",\n",
    "    question_text_key=\"question_text\",\n",
    "    answer_text_key=\"answer\",\n",
    ")\n",
    "\n",
    "assertion_score.to_csv(output_dir / \"assertion_scores.csv\", index=False)\n",
    "\n",
    "summary_by_assertion = (\n",
    "    assertion_score.groupby([\"question\", \"assertion\"])\n",
    "    .agg(score=(\"score\", lambda x: int(x.mean() > 0.5)), scores=(\"score\", list))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "summary_by_question = (\n",
    "    summary_by_assertion.groupby([\"question\"])\n",
    "    .agg(\n",
    "        success=(\"score\", lambda x: (x == 1).sum()),\n",
    "        fail=(\"score\", lambda x: (x == 0).sum()),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "summary_by_assertion[\"score_mean\"] = summary_by_assertion[\"scores\"].apply(\n",
    "    lambda x: np.mean(x) if len(x) > 0 else 0.0\n",
    ")\n",
    "summary_by_assertion[\"score_std\"] = summary_by_assertion[\"scores\"].apply(\n",
    "    lambda x: np.std(x) if len(x) > 0 else 0.0\n",
    ")\n",
    "summary_by_assertion = summary_by_assertion.drop(columns=[\"scores\"])\n",
    "\n",
    "print_df(\n",
    "    summary_by_question,\n",
    "    \"Assertion Scores Summary by Question\",\n",
    ")\n",
    "\n",
    "failed_assertions: pd.DataFrame = cast(\n",
    "    pd.DataFrame, summary_by_assertion[summary_by_assertion[\"score\"] == 0]\n",
    ")\n",
    "\n",
    "failed_assertions = failed_assertions.drop(columns=[\"score\"])\n",
    "\n",
    "if len(failed_assertions) > 0:\n",
    "    print_df(\n",
    "        failed_assertions,\n",
    "        f\"[bold red]{failed_assertions.shape[0]} Failed Assertions[/bold red]\",\n",
    "    )\n",
    "    rich_print(\n",
    "        f\"[bold red]{failed_assertions.shape[0]} assertions failed. See {output_dir / 'assertion_scores.csv'} for details.[/bold red]\"\n",
    "    )\n",
    "else:\n",
    "    rich_print(\"[bold green]All assertions passed.[/bold green]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fe36b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
